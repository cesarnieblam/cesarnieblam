## AMD
> Note: AMD GPUs can't be used with windows. Following instructions work for linux only.

1. `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.4.2`
2. `pip uninstall onnxruntime`
3. `git clone https://github.com/microsoft/onnxruntime && cd onnxruntime`
4. `./build.sh --config Release --build_wheel --update --build --parallel --cmake_extra_defines CMAKE_PREFIX_PATH=/opt/rocm/lib/cmake ONNXRUNTIME_VERSION=$ONNXRUNTIME_VERSION onnxruntime_BUILD_UNIT_TESTS=off --use_rocm --rocm_home=/opt/rocm`
5. `pip install build/Linux/Release/dist/*.whl`

[Having trouble?](https://github.com/s0md3v/roop/wiki/Troubleshooting)

## NVIDIA
If you are on windows, [this detailed explanation](https://github.com/s0md3v/roop/issues/68#issuecomment-1567722709) will most likely work for you. If you are on linux, well read on:

Recommended versions: `ONNX Runtime 1.9.0 CUDA EP - CUDA 11.4.3+cuDNN 8.2.4.15`

1. install CUDA toolkit from [here](https://developer.nvidia.com/cuda-11-4-3-download-archive)
2. install CUDNN from [here](https://developer.nvidia.com/rdp/cudnn-download)
3. `pip uninstall onnxruntime onnxruntime-gpu`
4. `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu114`
3. `pip install onnxruntime-gpu`

[Having trouble?](https://github.com/s0md3v/roop/wiki/Troubleshooting)

## Mac
1. `brew install wget cmake protobuf git git-lfs`
2. `git clone https://github.com/cansik/onnxruntime-silicon && cd onnxruntime-silicon`
3. `./build-macos.sh`
4. `pip install dist/*whl` (this step may need improvisation)

[Having trouble?](https://github.com/s0md3v/roop/wiki/Troubleshooting)

## Intel
1. `pip uninstall onnxruntime`
2. install the intel-specific onnxruntime called [OpenVINO](https://onnxruntime.ai/docs/execution-providers/OpenVINO-ExecutionProvider.html#install)

[Having trouble?](https://github.com/s0md3v/roop/wiki/Troubleshooting)