### CUDA Execution Provider (Nvidia)

1. Install [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-11-8-0-download-archive)

2. Install dependencies:

```
pip uninstall onnxruntime onnxruntime-gpu
pip install onnxruntime-gpu==1.15.1
```

3. Usage in case the provider is available:

```
python run.py --execution-provider cuda
```

### CoreML Execution Provider (Apple Silicon)

1. Install dependencies:

```
pip uninstall onnxruntime onnxruntime-silicon
pip install onnxruntime-silicon==1.13.1
```

2. Usage in case the provider is available:

```
python run.py --execution-provider coreml
```

### DirectML Execution Provider (Windows)

1. Install dependencies:

```
pip uninstall onnxruntime onnxruntime-directml
pip install onnxruntime-directml==1.15.1
```

### OpenVINOâ„¢ Execution Provider (Intel)

1. Install dependencies:

```
pip uninstall onnxruntime onnxruntime-openvino
pip install onnxruntime-openvino==1.15.0
```

2. Usage in case the provider is available:

```
python run.py --execution-provider openvino
```

### ROCm Execution Provider (AMD)

1. Build and install custom wheels from the [onnxruntime](https://github.com/microsoft/onnxruntime) source.

2. Usage in case the provider is available:

```
python run.py --execution-provider rocm
```